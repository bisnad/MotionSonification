{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bf0c862-18d5-4355-bd3b-d884d333c69c",
   "metadata": {},
   "source": [
    "# Audio Autoencoder (RNN Version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b84300-6339-4f17-b3a8-e6cd1ae11eea",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea8041f-9c87-4c59-b621-e66be00cafae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "import torchaudio\n",
    "import simpleaudio as sa\n",
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os, time\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from vocos import Vocos\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a8d7b-b3a1-4bb6-adda-74229bbe52d5",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081551d-ad45-4aae-86f9-5b2863d0ea87",
   "metadata": {},
   "source": [
    "## Compute Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad53149b-6deb-434e-bd33-7df4f42e0306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f652c9b-172c-4400-a2ee-c975e20a6299",
   "metadata": {},
   "source": [
    "## Audio Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6b10ba9-b15c-45b7-a513-290eaac1869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83cc152d6c3a4ba5929beb6b36f21b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='../../../Data/sounds/', description='Audio File Path:', style=TextStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862ba0da0bad48b1a335faf7ef648d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Night_and_Day_by_Virginia_Woolf_48khz.wav', description='Audio Files:', layout=Layout(width='5…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5adbef1821d48339142643d78113476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=48000, description='Audio Sample Rate:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc584923ead464aa4310657ecd75bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=1, description='Audio Channel Count:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b91b8213674978bf921c8cda79e307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=2048, description='Audio Window Length:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_file_path = \"../../../Data/sounds/\"\n",
    "audio_files = [\"Night_and_Day_by_Virginia_Woolf_48khz.wav\"]\n",
    "audio_sample_rate = 48000 # numer of audio samples per sec\n",
    "audio_channel_count = 1\n",
    "audio_window_length = 2048 # this results in 9 mel spectra\n",
    "\n",
    "audio_file_path_gui = widgets.Text(value=audio_file_path, description=\"Audio File Path:\", style={'description_width': 'initial'}) \n",
    "\n",
    "audio_files_gui = widgets.Textarea(\n",
    "    value=','.join(audio_files),\n",
    "    placeholder='Enter file names separated by commas',\n",
    "    description='Audio Files:',\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "audio_sample_rate_gui = widgets.IntText(value=audio_sample_rate, description=\"Audio Sample Rate:\", style={'description_width': 'initial'})\n",
    "audio_channel_count_gui = widgets.IntText(value=audio_channel_count, description=\"Audio Channel Count:\", style={'description_width': 'initial'})\n",
    "audio_window_length_gui = widgets.IntText(value=audio_window_length, description=\"Audio Window Length:\", style={'description_width': 'initial'})\n",
    "\n",
    "display(audio_file_path_gui)\n",
    "display(audio_files_gui)\n",
    "display(audio_sample_rate_gui)\n",
    "display(audio_channel_count_gui)\n",
    "display(audio_window_length_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8205c5d7-71f8-4607-ac91-4a36b77c9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = audio_file_path_gui.value\n",
    "audio_files = re.split(r'\\s*,\\s*', audio_files_gui.value)\n",
    "audio_sample_rate = audio_sample_rate_gui.value\n",
    "audio_channel_count = audio_channel_count_gui.value\n",
    "audio_window_length = audio_window_length_gui.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb003c7-f3bd-4cb0-acf4-e05fcef60e00",
   "metadata": {},
   "source": [
    "## Autoencoder Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b447e072-b9fa-4b7c-8c58-fb57235c7c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d9227637b34afaa39b380d1c98f2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=32, description='Latent Dimension:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea7dbc510fb42a8899ed1b43743b429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=2, description='LSTM Layer Count:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8653fc3710614586aefd7cfdbb6c471f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=512, description='LSTM Layer Size:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3df56897c6435293bfcbec175ff1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='512', description='Dense Layer Sizes:', layout=Layout(width='50%'), placeholder='Enter dense l…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711c9bd3c81b4fbdbc6c475c9961a606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='results/weights/encoder_weights_epoch_400', description='Encoder Weights File:', style=TextStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf6a2ad0c154c64a813346523236077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='results/weights/decoder_weights_epoch_400', description='Decoder Weights File:', style=TextStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_dim = 32\n",
    "sequence_length = None # will be calculate automatically\n",
    "ae_rnn_layer_count = 2\n",
    "ae_rnn_layer_size = 512\n",
    "ae_dense_layer_sizes = [ 512 ]\n",
    "\n",
    "save_weights = True\n",
    "load_weights = False\n",
    "encoder_weights_file = \"results/weights/encoder_weights_epoch_400\"\n",
    "decoder_weights_file = \"results/weights/decoder_weights_epoch_400\"\n",
    "\n",
    "latent_dim_gui = widgets.IntText(value=latent_dim, description=\"Latent Dimension:\", style={'description_width': 'initial'})\n",
    "ae_rnn_layer_count_gui = widgets.IntText(value=ae_rnn_layer_count, description=\"LSTM Layer Count:\", style={'description_width': 'initial'})\n",
    "ae_rnn_layer_size_gui = widgets.IntText(value=ae_rnn_layer_size, description=\"LSTM Layer Size:\", style={'description_width': 'initial'})\n",
    "\n",
    "ae_dense_layer_sizes_gui = widgets.Textarea(\n",
    "    value=','.join(list(map(str, ae_dense_layer_sizes))),\n",
    "    placeholder='Enter dense layer sizes separated by commas',\n",
    "    description='Dense Layer Sizes:',\n",
    "    layout=widgets.Layout(width='50%'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "save_weights_gui = widgets.Checkbox(\n",
    "    value=save_weights,\n",
    "    description='Save Weights',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "load_weights_gui = widgets.Checkbox(\n",
    "    value=load_weights,\n",
    "    description='Load Weights',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "encoder_weights_file_gui = widgets.Text(value=encoder_weights_file, description=\"Encoder Weights File:\", style={'description_width': 'initial'}) \n",
    "decoder_weights_file_gui = widgets.Text(value=decoder_weights_file, description=\"Decoder Weights File:\", style={'description_width': 'initial'}) \n",
    "\n",
    "display(latent_dim_gui)\n",
    "display(ae_rnn_layer_count_gui)\n",
    "display(ae_rnn_layer_size_gui)\n",
    "display(ae_dense_layer_sizes_gui)\n",
    "display(save_weights_gui)\n",
    "display(load_weights_gui)\n",
    "display(encoder_weights_file_gui)\n",
    "display(decoder_weights_file_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03cf6272-0a55-41e6-be76-81dbe3a70994",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = latent_dim_gui.value\n",
    "ae_rnn_layer_count = ae_rnn_layer_count_gui.value\n",
    "ae_rnn_layer_size = ae_rnn_layer_size_gui.value\n",
    "ae_dense_layer_sizes  = [int(s) for s in re.split(r\"\\s*,\\s*\", ae_dense_layer_sizes_gui.value) if s.strip()]\n",
    "save_weights = save_weights_gui.value\n",
    "load_weights = load_weights_gui.value\n",
    "encoder_weights_file = encoder_weights_file_gui.value\n",
    "decoder_weights_file = decoder_weights_file_gui.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534771a6-d3af-46b6-a18e-ec0305a35505",
   "metadata": {},
   "source": [
    "## Training Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bba3484-5f9c-4784-af4c-27f4faea61d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b225027d0cb842b88630c76287b361cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=100000, description='Dataset Size:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637b8d8ec574412d8cb54806e019255e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=32, description='Batch Size:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86298c47d6844abbd9e93e8f8e66e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0001, description='Autoencoder Learning Rate:', style=DescriptionStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249e178ce89c42ab963b3f6c87420ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=5.0, description='Autoencoder Reconstruction Loss Scale:', style=DescriptionStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2134f95e607468489f3fac490549bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0, description='Minimum Beta Factor:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547bf6ca4f62401db12af09a4d0c730c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.1, description='Maximum Beta Factor:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf277969ab948d5a803ff07f26a9932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=100, description='Cycle Duration for Beta Factor:', style=DescriptionStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca81fdb1e72f424e9924ad78ffd7f13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=20, description='Duration for Minimum Beta Factor:', style=DescriptionStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009b9b8b2b4642a0a9bc902dc79f6ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=20, description='Duration for Maximum Beta Factor:', style=DescriptionStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe74dd066b514e118790a8a325cc406e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=400, description='Number of Training Epochs:', style=DescriptionStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cd0dc06fea4c6daedb432eedf98bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=50, description='Model Save Interval:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_count = 100000\n",
    "batch_size = 32\n",
    "\n",
    "ae_learning_rate = 1e-4\n",
    "ae_rec_loss_scale = 5.0\n",
    "ae_beta = 0.0 # will be calculated\n",
    "ae_beta_cycle_duration = 100\n",
    "ae_beta_min_const_duration = 20\n",
    "ae_beta_max_const_duration = 20\n",
    "ae_min_beta = 0.0\n",
    "ae_max_beta = 0.1\n",
    "\n",
    "epochs = 400\n",
    "model_save_interval = 50\n",
    "save_history = True\n",
    "\n",
    "data_count_gui = widgets.IntText(value=data_count, description=\"Dataset Size:\", style={'description_width': 'initial'})\n",
    "batch_size_gui = widgets.IntText(value=batch_size, description=\"Batch Size:\", style={'description_width': 'initial'})\n",
    "ae_learning_rate_gui = widgets.FloatText(value=ae_learning_rate, description=\"Autoencoder Learning Rate:\", style={'description_width': 'initial'})\n",
    "ae_rec_loss_scale_gui = widgets.FloatText(value=ae_rec_loss_scale, description=\"Autoencoder Reconstruction Loss Scale:\", style={'description_width': 'initial'})\n",
    "ae_min_beta_gui = widgets.FloatText(value=ae_min_beta, description=\"Minimum Beta Factor:\", style={'description_width': 'initial'})\n",
    "ae_max_beta_gui = widgets.FloatText(value=ae_max_beta, description=\"Maximum Beta Factor:\", style={'description_width': 'initial'})\n",
    "ae_beta_cycle_duration_gui = widgets.IntText(value=ae_beta_cycle_duration, description=\"Cycle Duration for Beta Factor:\", style={'description_width': 'initial'})\n",
    "ae_beta_min_const_duration_gui = widgets.IntText(value=ae_beta_min_const_duration, description=\"Duration for Minimum Beta Factor:\", style={'description_width': 'initial'})\n",
    "ae_beta_max_const_duration_gui = widgets.IntText(value=ae_beta_min_const_duration, description=\"Duration for Maximum Beta Factor:\", style={'description_width': 'initial'})\n",
    "epochs_gui = widgets.IntText(value=epochs, description=\"Number of Training Epochs:\", style={'description_width': 'initial'})\n",
    "model_save_interval_gui = widgets.IntText(value=model_save_interval, description=\"Model Save Interval:\", style={'description_width': 'initial'})\n",
    "\n",
    "save_history_gui = widgets.Checkbox(\n",
    "    value=save_history,\n",
    "    description='Save Training History',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "display(data_count_gui)\n",
    "display(batch_size_gui)\n",
    "display(ae_learning_rate_gui)\n",
    "display(ae_rec_loss_scale_gui)\n",
    "display(ae_min_beta_gui)\n",
    "display(ae_max_beta_gui)\n",
    "display(ae_beta_cycle_duration_gui)\n",
    "display(ae_beta_min_const_duration_gui)\n",
    "display(ae_beta_max_const_duration_gui)\n",
    "display(epochs_gui)\n",
    "display(model_save_interval_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86e1fdfe-b6ad-440e-97d6-036a417e6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count = data_count_gui.value\n",
    "batch_size = batch_size_gui.value\n",
    "ae_learning_rate = ae_learning_rate_gui.value\n",
    "ae_rec_loss_scale = ae_rec_loss_scale_gui.value\n",
    "ae_beta_cycle_duration = ae_beta_cycle_duration_gui.value\n",
    "ae_beta_min_const_duration = ae_beta_min_const_duration_gui.value\n",
    "ae_beta_max_const_duration = ae_beta_max_const_duration_gui.value\n",
    "ae_min_beta = ae_min_beta_gui.value\n",
    "ae_max_beta = ae_max_beta_gui.value\n",
    "epochs = epochs_gui.value\n",
    "model_save_interval = model_save_interval_gui.value\n",
    "save_history = save_history_gui.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa14b8b-7a1d-47e0-929e-3d30ca3735b0",
   "metadata": {},
   "source": [
    "## Create Vocoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6fe13d-3dc5-43c5-9ddf-6ea294acbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocos = Vocos.from_pretrained(\"kittn/vocos-mel-48khz-alpha1\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09373480-fa2c-4192-b21d-efe96f31b075",
   "metadata": {},
   "source": [
    "## Determine Number of Mel Filters and Mel Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fd84bc3-477b-4d98-b9eb-3901481d1c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_window_length  2048  mel_count  9  mel_filter_count  128\n"
     ]
    }
   ],
   "source": [
    "vocoder_features = vocos.feature_extractor(torch.rand(size=(1, audio_window_length), dtype=torch.float32).to(device))\n",
    "mel_count = vocoder_features.shape[-1]\n",
    "mel_filter_count = vocoder_features.shape[1]\n",
    "sequence_length = mel_count\n",
    "\n",
    "print(\"audio_window_length \", audio_window_length, \" mel_count \", mel_count, \" mel_filter_count \", mel_filter_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0d1940-be77-416c-a02e-565e7075e13a",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0431bfa-8227-448d-8556-9dbc4337595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_item s  torch.Size([2048])\n",
      "batch_x s  torch.Size([32, 2048])\n"
     ]
    }
   ],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, audio_file_path, audio_files, audio_window_length, audio_data_count):\n",
    "        self.audio_file_path = audio_file_path\n",
    "        self.audio_files = audio_files\n",
    "        self.audio_window_length = audio_window_length\n",
    "        self.audio_data_count = audio_data_count\n",
    "        \n",
    "        self.audio_waveforms = []\n",
    "        \n",
    "        for audio_file in self.audio_files:\n",
    "            audio_waveform, _ = torchaudio.load(self.audio_file_path + \"/\" + audio_file)\n",
    "            self.audio_waveforms.append(audio_waveform)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.audio_data_count\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        audio_index = torch.randint(0, len(self.audio_waveforms), size=(1,))\n",
    "        audio_waveform = self.audio_waveforms[audio_index]\n",
    "        \n",
    "        audio_length = audio_waveform.shape[1]\n",
    "        audio_excerpt_start = torch.randint(0, audio_length - self.audio_window_length, size=(1,))\n",
    "        audio_excerpt = audio_waveform[:, audio_excerpt_start:audio_excerpt_start+audio_window_length]\n",
    "        audio_excerpt = audio_excerpt[0]\n",
    "        \n",
    "        return audio_excerpt\n",
    "\n",
    "\n",
    "full_dataset = AudioDataset(audio_file_path, audio_files, audio_window_length, data_count)\n",
    "dataset_size = len(full_dataset)\n",
    "\n",
    "data_item = full_dataset[0]\n",
    "\n",
    "print(\"data_item s \", data_item.shape)\n",
    "\n",
    "dataloader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "batch_x = next(iter(dataloader))\n",
    "\n",
    "print(\"batch_x s \", batch_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775389d9-1d3e-4f55-a824-8487798a74f8",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae531e8-4cec-442d-a30b-7c89436775ef",
   "metadata": {},
   "source": [
    "## Create Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "764960dc-978f-4a22-9865-19c82fa2bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (rnn_layers): Sequential(\n",
      "    (encoder_rnn_0): LSTM(128, 512, num_layers=2, batch_first=True)\n",
      "  )\n",
      "  (dense_layers): Sequential(\n",
      "    (encoder_dense_0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (encoder_dense_relu_0): ReLU()\n",
      "  )\n",
      "  (fc_mu): Linear(in_features=512, out_features=32, bias=True)\n",
      "  (fc_std): Linear(in_features=512, out_features=32, bias=True)\n",
      ")\n",
      "audio_batch s  torch.Size([32, 2048])\n",
      "audio_batch_mels s  torch.Size([32, 1, 128, 9])\n",
      "audio_encoder_in s  torch.Size([32, 9, 128])\n",
      "audio_encoder_out_mu s  torch.Size([32, 32])\n",
      "audio_encoder_out_std s  torch.Size([32, 32])\n",
      "audio_encoder_out s  torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, sequence_length, mel_filter_count, latent_dim, rnn_layer_count, rnn_layer_size, dense_layer_sizes):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.sequence_length = sequence_length\n",
    "        self.mel_filter_count = mel_filter_count\n",
    "        self.latent_dim = latent_dim\n",
    "        self.rnn_layer_count = rnn_layer_count\n",
    "        self.rnn_layer_size = rnn_layer_size \n",
    "        self.dense_layer_sizes = dense_layer_sizes\n",
    "    \n",
    "        # create recurrent layers\n",
    "        rnn_layers = []\n",
    "        rnn_layers.append((\"encoder_rnn_0\", nn.LSTM(self.mel_filter_count, self.rnn_layer_size, self.rnn_layer_count, batch_first=True)))\n",
    "        \n",
    "        self.rnn_layers = nn.Sequential(OrderedDict(rnn_layers))\n",
    "        \n",
    "        # create dense layers\n",
    "        \n",
    "        dense_layers = []\n",
    "        \n",
    "        dense_layers.append((\"encoder_dense_0\", nn.Linear(self.rnn_layer_size, self.dense_layer_sizes[0])))\n",
    "        dense_layers.append((\"encoder_dense_relu_0\", nn.ReLU()))\n",
    "        \n",
    "        dense_layer_count = len(self.dense_layer_sizes)\n",
    "        for layer_index in range(1, dense_layer_count):\n",
    "            dense_layers.append((\"encoder_dense_{}\".format(layer_index), nn.Linear(self.dense_layer_sizes[layer_index-1], self.dense_layer_sizes[layer_index])))\n",
    "            dense_layers.append((\"encoder_dense_relu_{}\".format(layer_index), nn.ReLU()))\n",
    "            \n",
    "        self.dense_layers = nn.Sequential(OrderedDict(dense_layers))\n",
    "        \n",
    "        # create final dense layers\n",
    "            \n",
    "        self.fc_mu = nn.Linear(self.dense_layer_sizes[-1], self.latent_dim)\n",
    "        self.fc_std = nn.Linear(self.dense_layer_sizes[-1], self.latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print(\"x 1 \", x.shape)\n",
    "        \n",
    "        x, (_, _) = self.rnn_layers(x)\n",
    "        \n",
    "        #print(\"x 2 \", x.shape)\n",
    "        \n",
    "        x = x[:, -1, :] # only last time step \n",
    "        \n",
    "        #print(\"x 3 \", x.shape)\n",
    "        \n",
    "        x = self.dense_layers(x)\n",
    "        \n",
    "        #print(\"x 3 \", x.shape)\n",
    "        \n",
    "        mu = self.fc_mu(x)\n",
    "        std = self.fc_std(x)\n",
    "        \n",
    "        #print(\"mu s \", mu.shape, \" lvar s \", log_var.shape)\n",
    "    \n",
    "        return mu, std\n",
    "\n",
    "    def reparameterize(self, mu, std):\n",
    "        z = mu + std*torch.randn_like(std)\n",
    "        return z\n",
    "    \n",
    "encoder = Encoder(sequence_length, mel_filter_count, latent_dim, ae_rnn_layer_count, ae_rnn_layer_size, ae_dense_layer_sizes).to(device)\n",
    "\n",
    "print(encoder)\n",
    "\n",
    "if load_weights and encoder_weights_file:\n",
    "    encoder.load_state_dict(torch.load(encoder_weights_file, map_location=device))\n",
    "\n",
    "# test encoder\n",
    "audio_batch = next(iter(dataloader)).to(device)\n",
    "audio_batch_mels = vocos.feature_extractor(audio_batch.unsqueeze(1))\n",
    "audio_encoder_in = audio_batch_mels.squeeze(1).permute((0, 2, 1))\n",
    "audio_encoder_out_mu, audio_encoder_out_std = encoder(audio_encoder_in)\n",
    "audio_encoder_out = encoder.reparameterize(audio_encoder_out_mu, audio_encoder_out_std)\n",
    "\n",
    "print(\"audio_batch s \", audio_batch.shape)\n",
    "print(\"audio_batch_mels s \", audio_batch_mels.shape)\n",
    "print(\"audio_encoder_in s \", audio_encoder_in.shape)\n",
    "print(\"audio_encoder_out_mu s \", audio_encoder_out_mu.shape)\n",
    "print(\"audio_encoder_out_std s \", audio_encoder_out_std.shape)\n",
    "print(\"audio_encoder_out s \", audio_encoder_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe293f-61c8-4d66-b0d6-79e336b3cac9",
   "metadata": {},
   "source": [
    "## Create Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6b2e46f-0a8e-4a80-90bd-35443fd59dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (dense_layers): Sequential(\n",
      "    (decoder_dense_0): Linear(in_features=32, out_features=512, bias=True)\n",
      "    (decoder_relu_0): ReLU()\n",
      "  )\n",
      "  (rnn_layers): Sequential(\n",
      "    (decoder_rnn_0): LSTM(512, 512, num_layers=2, batch_first=True)\n",
      "  )\n",
      "  (final_layers): Sequential(\n",
      "    (decoder_dense_1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  )\n",
      ")\n",
      "audio_decoder_in s  torch.Size([32, 32])\n",
      "audio_decoder_out s  torch.Size([32, 9, 128])\n",
      "audio_features s  torch.Size([32, 128, 9])\n",
      "audio_batch s  torch.Size([32, 2048])\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, sequence_length, mel_filter_count, latent_dim, rnn_layer_count, rnn_layer_size, dense_layer_sizes):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.sequence_length = sequence_length\n",
    "        self.mel_filter_count = mel_filter_count\n",
    "        self.latent_dim = latent_dim\n",
    "        self.rnn_layer_size = rnn_layer_size\n",
    "        self.rnn_layer_count = rnn_layer_count\n",
    "        self.dense_layer_sizes = dense_layer_sizes\n",
    "\n",
    "        # create dense layers\n",
    "        dense_layers = []\n",
    "        \n",
    "        dense_layers.append((\"decoder_dense_0\", nn.Linear(latent_dim, self.dense_layer_sizes[0])))\n",
    "        dense_layers.append((\"decoder_relu_0\", nn.ReLU()))\n",
    "\n",
    "        dense_layer_count = len(self.dense_layer_sizes)\n",
    "        for layer_index in range(1, dense_layer_count):\n",
    "            dense_layers.append((\"decoder_dense_{}\".format(layer_index), nn.Linear(self.dense_layer_sizes[layer_index-1], self.dense_layer_sizes[layer_index])))\n",
    "            dense_layers.append((\"decoder_dense_relu_{}\".format(layer_index), nn.ReLU()))\n",
    " \n",
    "        self.dense_layers = nn.Sequential(OrderedDict(dense_layers))\n",
    "        \n",
    "        # create rnn layers\n",
    "        rnn_layers = []\n",
    "\n",
    "        rnn_layers.append((\"decoder_rnn_0\", nn.LSTM(self.dense_layer_sizes[-1], self.rnn_layer_size, self.rnn_layer_count, batch_first=True)))\n",
    "        \n",
    "        self.rnn_layers = nn.Sequential(OrderedDict(rnn_layers))\n",
    "        \n",
    "        # final output dense layer\n",
    "        final_layers = []\n",
    "        \n",
    "        final_layers.append((\"decoder_dense_{}\".format(dense_layer_count), nn.Linear(self.rnn_layer_size, self.mel_filter_count)))\n",
    "        \n",
    "        self.final_layers = nn.Sequential(OrderedDict(final_layers))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"x 1 \", x.size())\n",
    "        \n",
    "        # dense layers\n",
    "        x = self.dense_layers(x)\n",
    "        #print(\"x 2 \", x.size())\n",
    "        \n",
    "        # repeat vector\n",
    "        x = torch.unsqueeze(x, dim=1)\n",
    "        x = x.repeat(1, sequence_length, 1)\n",
    "        #print(\"x 3 \", x.size())\n",
    "        \n",
    "        # rnn layers\n",
    "        x, (_, _) = self.rnn_layers(x)\n",
    "        #print(\"x 4 \", x.size())\n",
    "        \n",
    "        # final time distributed dense layer\n",
    "        x_reshaped = x.contiguous().view(-1, self.rnn_layer_size)  # (batch_size * sequence, input_size)\n",
    "        #print(\"x 5 \", x_reshaped.size())\n",
    "        \n",
    "        yhat = self.final_layers(x_reshaped)\n",
    "        #print(\"yhat 1 \", yhat.size())\n",
    "        \n",
    "        yhat = yhat.contiguous().view(-1, self.sequence_length, self.mel_filter_count)\n",
    "        #print(\"yhat 2 \", yhat.size())\n",
    "\n",
    "        return yhat\n",
    "\n",
    "ae_dense_layer_sizes_reversed = ae_dense_layer_sizes.copy()\n",
    "ae_dense_layer_sizes_reversed.reverse()\n",
    "\n",
    "decoder = Decoder(sequence_length, mel_filter_count, latent_dim, ae_rnn_layer_count, ae_rnn_layer_size, ae_dense_layer_sizes_reversed).to(device)\n",
    "\n",
    "print(decoder)\n",
    "\n",
    "if load_weights and decoder_weights_file:\n",
    "    decoder.load_state_dict(torch.load(decoder_weights_file, map_location=device))\n",
    "\n",
    "# test decoder\n",
    "audio_decoder_in = audio_encoder_out\n",
    "audio_decoder_out = decoder(audio_decoder_in)\n",
    "audio_features = audio_decoder_out.permute((0, 2, 1))\n",
    "\n",
    "audio_features = audio_features.squeeze(1)\n",
    "audio_batch = vocos.decode(audio_features)\n",
    "\n",
    "print(\"audio_decoder_in s \", audio_decoder_in.shape)\n",
    "print(\"audio_decoder_out s \", audio_decoder_out.shape)\n",
    "print(\"audio_features s \", audio_features.shape)\n",
    "print(\"audio_batch s \", audio_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32706cf1-367d-4b1e-adf1-5814b71ed2f3",
   "metadata": {},
   "source": [
    "## Create Beta Factor Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "631aaafb-fa70-40c3-9b24-ad23002cdc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17728dcf0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calc_ae_beta_values():\n",
    "    \n",
    "    ae_beta_values = []\n",
    "\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        cycle_step = e % ae_beta_cycle_duration\n",
    "        \n",
    "        #print(\"cycle_step \", cycle_step)\n",
    "\n",
    "        if cycle_step < ae_beta_min_const_duration:\n",
    "            ae_beta_value = ae_min_beta\n",
    "            ae_beta_values.append(ae_beta_value)\n",
    "        elif cycle_step > ae_beta_cycle_duration - ae_beta_max_const_duration:\n",
    "            ae_beta_value = ae_max_beta\n",
    "            ae_beta_values.append(ae_beta_value)\n",
    "        else:\n",
    "            lin_step = cycle_step - ae_beta_min_const_duration\n",
    "            ae_beta_value = ae_min_beta + (ae_max_beta - ae_min_beta) * lin_step / (ae_beta_cycle_duration - ae_beta_min_const_duration - ae_beta_max_const_duration)\n",
    "            ae_beta_values.append(ae_beta_value)\n",
    "            \n",
    "    return ae_beta_values\n",
    "\n",
    "ae_beta_values = calc_ae_beta_values()\n",
    "\n",
    "plt.plot(ae_beta_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce906d-01b1-4160-8ee3-a3151516d059",
   "metadata": {},
   "source": [
    "## Create Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc2f2957-8300-4f20-9258-43e07afc56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=ae_learning_rate)\n",
    "ae_scheduler = torch.optim.lr_scheduler.StepLR(ae_optimizer, step_size=50, gamma=0.316)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae74d9d-f1fc-4dfd-9f33-bca14601b922",
   "metadata": {},
   "source": [
    "## Create Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1011a857-2d6c-40f1-9a6f-def914a7affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "cross_entropy = nn.BCELoss()\n",
    "\n",
    "def variational_loss(mu, std):\n",
    "    #returns the varialtional loss from arguments mean and standard deviation std\n",
    "    #see also: see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    #https://arxiv.org/abs/1312.6114\n",
    "    vl=-0.5*torch.mean(1+ 2*torch.log(std)-mu.pow(2) -(std.pow(2)))\n",
    "    return vl\n",
    "\n",
    "def ae_rec_loss(y, yhat):\n",
    "    \n",
    "    al = mse_loss(yhat, y)\n",
    "\n",
    "    return al\n",
    "\n",
    "# autoencoder loss function\n",
    "def ae_loss(y, yhat, mu, std):\n",
    "\n",
    "    # kld loss\n",
    "    _ae_kld_loss = variational_loss(mu, std)\n",
    "    \n",
    "    # ae rec loss\n",
    "    _ae_rec_loss = ae_rec_loss(y, yhat)\n",
    "    \n",
    "    _total_loss = 0.0\n",
    "    _total_loss += _ae_rec_loss * ae_rec_loss_scale\n",
    "    _total_loss += _ae_kld_loss * ae_beta\n",
    "    \n",
    "    return _total_loss, _ae_rec_loss, _ae_kld_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad61ed-824d-45e8-93d1-aa135968b006",
   "metadata": {},
   "source": [
    "## Create Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8131e06-e962-42c9-806d-0064ca249980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_train_step(target_features):\n",
    "    \n",
    "    #print(\"train step target_audio \", target_audio.shape)\n",
    "    audio_encoder_out_mu, audio_encoder_out_std = encoder(target_features)\n",
    "    \n",
    "    mu = audio_encoder_out_mu\n",
    "    std = torch.nn.functional.softplus(audio_encoder_out_std) + 1e-6\n",
    "    decoder_input = encoder.reparameterize(mu, std)\n",
    " \n",
    "    pred_features_norm = decoder(decoder_input)\n",
    "    \n",
    "    _ae_loss, _ae_rec_loss, _ae_kld_loss = ae_loss(target_features, pred_features_norm, mu, std) \n",
    "    \n",
    "    # Backpropagation\n",
    "    ae_optimizer.zero_grad()\n",
    "    _ae_loss.backward()\n",
    "    \n",
    "    #torch.nn.utils.clip_grad_norm(encoder.parameters(), 0.01)\n",
    "    #torch.nn.utils.clip_grad_norm(decoder.parameters(), 0.01)\n",
    "\n",
    "    ae_optimizer.step()\n",
    "    \n",
    "    return _ae_loss, _ae_rec_loss, _ae_kld_loss\n",
    "\n",
    "def train(dataloader, epochs):\n",
    "    \n",
    "    global ae_beta\n",
    "    \n",
    "    loss_history = {}\n",
    "    loss_history[\"ae train\"] = []\n",
    "    loss_history[\"ae rec\"] = []\n",
    "    loss_history[\"ae kld\"] = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        ae_beta = ae_beta_values[epoch]\n",
    "        \n",
    "        #print(\"ae_kld_loss_scale \", ae_kld_loss_scale)\n",
    "        \n",
    "        ae_train_loss_per_epoch = []\n",
    "        ae_rec_loss_per_epoch = []\n",
    "        ae_kld_loss_per_epoch = []\n",
    "        \n",
    "        for train_batch in dataloader:\n",
    "            train_batch = train_batch.to(device)\n",
    "            train_batch = vocos.feature_extractor(train_batch.unsqueeze(1))\n",
    "            train_batch = train_batch.squeeze(1).permute((0, 2, 1))\n",
    "            \n",
    "            _ae_loss, _ae_rec_loss, _ae_kld_loss = ae_train_step(train_batch)\n",
    "            \n",
    "            _ae_loss = _ae_loss.detach().cpu().numpy()\n",
    "            _ae_rec_loss = _ae_rec_loss.detach().cpu().numpy()\n",
    "            _ae_kld_loss = _ae_kld_loss.detach().cpu().numpy()\n",
    "            \n",
    "            #print(\"_ae_prior_loss \", _ae_prior_loss)\n",
    "            \n",
    "            ae_train_loss_per_epoch.append(_ae_loss)\n",
    "            ae_rec_loss_per_epoch.append(_ae_rec_loss)\n",
    "            ae_kld_loss_per_epoch.append(_ae_kld_loss)\n",
    "\n",
    "        ae_train_loss_per_epoch = np.mean(np.array(ae_train_loss_per_epoch))\n",
    "        ae_rec_loss_per_epoch = np.mean(np.array(ae_rec_loss_per_epoch))\n",
    "        ae_kld_loss_per_epoch = np.mean(np.array(ae_kld_loss_per_epoch))\n",
    "        \n",
    "        if epoch % model_save_interval == 0 and save_weights == True:\n",
    "            torch.save(encoder.state_dict(), \"results/weights/encoder_weights_epoch_{}\".format(epoch))\n",
    "            torch.save(decoder.state_dict(), \"results/weights/decoder_weights_epoch_{}\".format(epoch))\n",
    "        \n",
    "        loss_history[\"ae train\"].append(ae_train_loss_per_epoch)\n",
    "        loss_history[\"ae rec\"].append(ae_rec_loss_per_epoch)\n",
    "        loss_history[\"ae kld\"].append(ae_kld_loss_per_epoch)\n",
    "        \n",
    "        print ('epoch {} : ae train: {:01.4f} rec {:01.4f} kld {:01.4f} time {:01.2f}'.format(epoch + 1, ae_train_loss_per_epoch, ae_rec_loss_per_epoch, ae_kld_loss_per_epoch, time.time()-start))\n",
    "    \n",
    "        ae_scheduler.step()\n",
    "        \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3ee69d-e0f7-4a5f-b67e-479ce60826fb",
   "metadata": {},
   "source": [
    "## Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca1399-ce2d-4f55-98f5-5d7b172fbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train(dataloader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5110d64-1de5-4176-82b3-22f1d9489974",
   "metadata": {},
   "source": [
    "## Save Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9783d0-c32c-4dc3-a6bc-af266e0c64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_loss_as_image(loss_history, image_file_name):\n",
    "    keys = list(loss_history.keys())\n",
    "    epochs = len(loss_history[keys[0]])\n",
    "    \n",
    "    for key in keys:\n",
    "        plt.plot(range(epochs), loss_history[key], label=key)\n",
    "        \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(image_file_name)\n",
    "    plt.show()\n",
    "\n",
    "def save_loss_as_csv(loss_history, csv_file_name):\n",
    "    with open(csv_file_name, 'w') as csv_file:\n",
    "        csv_columns = list(loss_history.keys())\n",
    "        csv_row_count = len(loss_history[csv_columns[0]])\n",
    "        \n",
    "        \n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=csv_columns, delimiter=',', lineterminator='\\n')\n",
    "        csv_writer.writeheader()\n",
    "    \n",
    "        for row in range(csv_row_count):\n",
    "        \n",
    "            csv_row = {}\n",
    "        \n",
    "            for key in loss_history.keys():\n",
    "                csv_row[key] = loss_history[key][row]\n",
    "\n",
    "            csv_writer.writerow(csv_row)\n",
    "\n",
    "save_loss_as_csv(loss_history, \"results/histories/history_{}.csv\".format(epochs))\n",
    "save_loss_as_image(loss_history, \"results/histories/history_{}.png\".format(epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c03f550-4aa9-43e2-8367-a427659ca85a",
   "metadata": {},
   "source": [
    "## Save Final Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ddc07-ab41-4f25-a38c-f0389dc1240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), \"results/weights/encoder_weights_epoch_{}\".format(epochs))\n",
    "torch.save(decoder.state_dict(), \"results/weights/decoder_weights_epoch_{}\".format(epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24edda33-1efb-4442-8ec1-9a2f340b0efa",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f60540e-e4cc-4a05-89b4-5e754944f4df",
   "metadata": {},
   "source": [
    "## Audio Reconstruction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e75d043-ac5f-4760-aa49-583c24638391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ref_audio_window(waveform_window, file_name):\n",
    "\n",
    "    torchaudio.save(\"{}\".format(file_name), waveform_window, audio_sample_rate)\n",
    "\n",
    "def create_voc_audio_window(waveform_window, file_name):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio_features = vocos.feature_extractor(waveform_window.to(device))\n",
    "        waveform_window_voc = vocos.decode(audio_features)\n",
    "    \n",
    "    torchaudio.save(\"{}\".format(file_name), waveform_window_voc.detach().cpu(), audio_sample_rate)\n",
    "\n",
    "def create_pred_audio_window(waveform_window, file_name):\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        audio_features = vocos.feature_extractor(waveform_window.to(device))\n",
    "        audio_encoder_in = audio_features.squeeze(1).permute((0, 2, 1))\n",
    "\n",
    "        audio_encoder_out_mu, audio_encoder_out_std = encoder(audio_encoder_in)\n",
    "        mu = audio_encoder_out_mu\n",
    "        std = torch.nn.functional.softplus(audio_encoder_out_std) + 1e-6\n",
    "        audio_encoder_out = encoder.reparameterize(mu, std)\n",
    "        audio_decoder_in = audio_encoder_out\n",
    "        audio_decoder_out = decoder(audio_decoder_in)\n",
    "        audio_features_pred = audio_decoder_out.permute((0, 2, 1))\n",
    "        audio_features_pred = audio_features_pred.squeeze(1)\n",
    "        audio_waveform_window_pred = vocos.decode(audio_features_pred)\n",
    "\n",
    "    torchaudio.save(\"{}\".format(file_name), audio_waveform_window_pred.detach().cpu(), audio_sample_rate)\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "def create_ref_audio(waveform, file_name):\n",
    "\n",
    "    torchaudio.save(\"{}\".format(file_name), waveform, audio_sample_rate)\n",
    "    \n",
    "    #print(\"waveform s \", waveform.shape)\n",
    "\n",
    "def create_voc_audio(waveform, file_name):\n",
    "    \n",
    "    waveform_length = waveform.shape[1]\n",
    "    audio_window_offset = audio_window_length // 2\n",
    "    audio_window_env = torch.hann_window(audio_window_length)\n",
    "    \n",
    "    audio_window_count = int(waveform_length - audio_window_length) // audio_window_offset\n",
    "    pred_audio_sequence = torch.zeros((waveform_length), dtype=torch.float32)\n",
    "    \n",
    "    #print(\"pred_audio_sequence s \", pred_audio_sequence.shape)\n",
    "    \n",
    "\n",
    "    for i in range(audio_window_count):\n",
    "        \n",
    "        window_start = i * audio_window_offset\n",
    "        window_end = window_start + audio_window_length\n",
    "        \n",
    "        waveform_window = waveform[:, window_start:window_end]\n",
    "        \n",
    "        #print(\"i \", i, \" target_audio s \", target_audio.shape)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            audio_features = vocos.feature_extractor(waveform_window.to(device))\n",
    "            waveform_window_voc = vocos.decode(audio_features)\n",
    "\n",
    "        #print(\"voc_audio s \", voc_audio.shape)\n",
    "        #print(\"grain_env s \", grain_env.shape)\n",
    "        \n",
    "        waveform_window_voc = waveform_window_voc.detach().cpu()\n",
    "\n",
    "        pred_audio_sequence[i*audio_window_offset:i*audio_window_offset + audio_window_length] += waveform_window_voc[0] * audio_window_env\n",
    "\n",
    "    torchaudio.save(\"{}\".format(file_name), torch.reshape(pred_audio_sequence, (1, -1)), audio_sample_rate)\n",
    "\n",
    "def create_pred_audio(waveform, file_name):\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    waveform_length = waveform.shape[1]\n",
    "    audio_window_offset = audio_window_length // 2\n",
    "    audio_window_env = torch.hann_window(audio_window_length)\n",
    "    \n",
    "    audio_window_count = int(waveform_length - audio_window_length) // audio_window_offset\n",
    "    pred_audio_sequence = torch.zeros((waveform_length), dtype=torch.float32)\n",
    "    \n",
    "    #print(\"pred_audio_sequence s \", pred_audio_sequence.shape)\n",
    "    \n",
    "    for i in range(audio_window_count):\n",
    "        \n",
    "        window_start = i * audio_window_offset\n",
    "        window_end = window_start + audio_window_length\n",
    "        \n",
    "        waveform_window = waveform[:, window_start:window_end]\n",
    "        \n",
    "        #print(\"i \", i, \" waveform_window s \", waveform_window.shape)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            audio_features = vocos.feature_extractor(waveform_window.to(device))\n",
    "            audio_encoder_in = audio_features.squeeze(1).permute((0, 2, 1))\n",
    "            \n",
    "            audio_encoder_out_mu, audio_encoder_out_std = encoder(audio_encoder_in)\n",
    "            mu = audio_encoder_out_mu\n",
    "            std = torch.nn.functional.softplus(audio_encoder_out_std) + 1e-6\n",
    "            \n",
    "            audio_encoder_out = encoder.reparameterize(mu, std)\n",
    "            \n",
    "            audio_decoder_in = audio_encoder_out\n",
    "            audio_decoder_out = decoder(audio_decoder_in)\n",
    "            audio_features_pred = audio_decoder_out.permute((0, 2, 1))\n",
    "            audio_features_pred = audio_features_pred.squeeze(1)\n",
    "            audio_waveform_window_pred = vocos.decode(audio_features_pred)\n",
    "\n",
    "        #print(\"voc_audio s \", voc_audio.shape)\n",
    "        #print(\"grain_env s \", grain_env.shape)\n",
    "        \n",
    "        audio_waveform_window_pred = audio_waveform_window_pred.detach().cpu()\n",
    "\n",
    "        pred_audio_sequence[i*audio_window_offset:i*audio_window_offset + audio_window_length] += audio_waveform_window_pred[0] * audio_window_env\n",
    "\n",
    "    torchaudio.save(\"{}\".format(file_name), torch.reshape(pred_audio_sequence, (1, -1)), audio_sample_rate)\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fe43b-16c3-43ba-9f50-cc45e1d7f167",
   "metadata": {},
   "source": [
    "## Perform Audio Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a84645d-17b9-406d-893f-78ff8b2405bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2091c2e28ad84c07a9d160cd25ef9cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Audio File:', options=('Night_and_Day_by_Virginia_Woolf_48khz.wav',), style=DescriptionS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7c3001f8d64d37a3656953364c6baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=50.0, description='Test Waveform Start Time (secs):', style=DescriptionStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d157997bded4413688b8c07510de32fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='20,120,240', description='Test Audio Start Times:', layout=Layout(width='50%'), placeholder='T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35439b7c63e34ba7a2ef08f1c35f5ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=20.0, description='Test Audio Duration (secs):', style=DescriptionStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_audio_file = audio_files[0]\n",
    "test_waveform_start_time = 50.0\n",
    "test_audio_start_times = [20, 120, 240]\n",
    "test_audio_duration = 20.0\n",
    "\n",
    "test_audio_file_gui = widgets.Dropdown(\n",
    "    options=[audio_file for audio_file in audio_files],\n",
    "    value=audio_files[0],  # default selected value\n",
    "    description='Audio File:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "test_waveform_start_time_gui = widgets.FloatText(value=test_waveform_start_time, description=\"Test Waveform Start Time (secs):\", style={'description_width': 'initial'})\n",
    "\n",
    "test_audio_start_times_gui = widgets.Textarea(\n",
    "    value=','.join(list(map(str, test_audio_start_times))),\n",
    "    placeholder='Test Audio Start Time (secs) separated by commas',\n",
    "    description='Test Audio Start Times:',\n",
    "    layout=widgets.Layout(width='50%'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "test_audio_duration_gui = widgets.FloatText(value=test_audio_duration, description=\"Test Audio Duration (secs):\", style={'description_width': 'initial'})\n",
    "\n",
    "\n",
    "display(test_audio_file_gui)\n",
    "display(test_waveform_start_time_gui)\n",
    "display(test_audio_start_times_gui)\n",
    "display(test_audio_duration_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61daa60c-c21e-48b5-b1fd-c1ed334a7698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "test_audio_file = test_audio_file_gui.value\n",
    "test_waveform_start_time = test_waveform_start_time_gui.value\n",
    "test_audio_start_times  = [int(s) for s in re.split(r\"\\s*,\\s*\", test_audio_start_times_gui.value) if s.strip()]\n",
    "test_audio_duration = test_audio_duration_gui.value\n",
    "\n",
    "test_waveform, _ = torchaudio.load(audio_file_path + \"/\" + test_audio_file)\n",
    "test_waveform_sample_index = int(audio_sample_rate * test_waveform_start_time)\n",
    "test_waveform_window = test_waveform[:, test_waveform_sample_index:test_waveform_sample_index+audio_window_length]\n",
    "\n",
    "create_ref_audio_window(test_waveform_window, \"results/audio/audio_window_orig.wav\")\n",
    "create_voc_audio_window(test_waveform_window, \"results/audio/audio_window_voc.wav\")\n",
    "create_pred_audio_window(test_waveform_window, \"results/audio/audio_window_pred_epoch_{}.wav\".format(epochs))\n",
    "\n",
    "for test_audio_start_time in test_audio_start_times:\n",
    "    start_time_sample_index = int(test_audio_start_time * audio_sample_rate)\n",
    "    end_time_sample_index = start_time_sample_index + int(test_audio_duration * audio_sample_rate)\n",
    "\n",
    "    create_ref_audio(test_waveform[:, start_time_sample_index:end_time_sample_index], \"results/audio/audio_ref_{}-{}.wav\".format(test_audio_start_time, (test_audio_start_time + test_audio_duration)))\n",
    "    create_voc_audio(test_waveform[:, start_time_sample_index:end_time_sample_index], \"results/audio/audio_voc_{}-{}.wav\".format(test_audio_start_time, (test_audio_start_time + test_audio_duration)))\n",
    "    create_pred_audio(test_waveform[:, start_time_sample_index:end_time_sample_index], \"results/audio/audio_pred_{}-{}_epoch_{}.wav\".format(test_audio_start_time, (test_audio_start_time + test_audio_duration), epochs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab8b3f-89d7-4f6e-971c-967194a81c25",
   "metadata": {},
   "source": [
    "## Latent Space Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421a9ad-7e9d-4b9b-beef-44fa44141c49",
   "metadata": {},
   "source": [
    "## Audio Encode and Decode Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1877a93-cbf4-4d4f-95f0-060db32acbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_audio(waveform):\n",
    "    \n",
    "    encoder.eval()\n",
    "    \n",
    "    waveform_length = waveform.shape[1]\n",
    "    audio_window_offset = audio_window_length // 2\n",
    "    audio_window_count = int(waveform_length - audio_window_length) // audio_window_offset\n",
    "    \n",
    "    latent_vectors = []\n",
    "\n",
    "    for i in range(audio_window_count):\n",
    "        \n",
    "        window_start = i * audio_window_offset\n",
    "        window_end = window_start + audio_window_length\n",
    "        \n",
    "        waveform_window = waveform[:, window_start:window_end]\n",
    "        \n",
    "        #print(\"i \", i, \" waveform_window s \", waveform_window.shape)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            audio_features = vocos.feature_extractor(waveform_window.to(device))\n",
    "            audio_encoder_in = audio_features.squeeze(1).permute((0, 2, 1))\n",
    "            \n",
    "            audio_encoder_out_mu, audio_encoder_out_std = encoder(audio_encoder_in)\n",
    "            mu = audio_encoder_out_mu\n",
    "            std = torch.nn.functional.softplus(audio_encoder_out_std) + 1e-6\n",
    "            \n",
    "            audio_encoder_out = encoder.reparameterize(mu, std)\n",
    "            \n",
    "        latent_vector = audio_encoder_out.squeeze(0)\n",
    "        latent_vector = latent_vector.detach().cpu().numpy()\n",
    "    \n",
    "        latent_vectors.append(latent_vector)\n",
    "    \n",
    "    encoder.train()\n",
    "        \n",
    "    return latent_vectors\n",
    "\n",
    "def decode_audio_encodings(encodings, file_name):\n",
    "    \n",
    "    decoder.eval()\n",
    "    \n",
    "    audio_window_offset = audio_window_length // 2\n",
    "    audio_window_env = torch.hann_window(audio_window_length)\n",
    "    \n",
    "    audio_window_count = len(encodings)\n",
    "    waveform_length = audio_window_count * audio_window_offset + audio_window_length\n",
    "    \n",
    "    pred_audio_sequence = torch.zeros((waveform_length), dtype=torch.float32)\n",
    "    \n",
    "    #print(\"pred_audio_sequence s \", pred_audio_sequence.shape)\n",
    "    \n",
    "    for i in range(audio_window_count):\n",
    "        \n",
    "        window_start = i * audio_window_offset\n",
    "        window_end = window_start + audio_window_length\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            audio_decoder_in = torch.Tensor(encodings[i]).unsqueeze(0).to(device)\n",
    "            audio_decoder_out = decoder(audio_decoder_in)\n",
    "            audio_features_pred = audio_decoder_out.permute((0, 2, 1))\n",
    "            audio_features_pred = audio_features_pred.squeeze(1)\n",
    "            audio_waveform_window_pred = vocos.decode(audio_features_pred)\n",
    "\n",
    "        #print(\"voc_audio s \", voc_audio.shape)\n",
    "        #print(\"grain_env s \", grain_env.shape)\n",
    "        \n",
    "        audio_waveform_window_pred = audio_waveform_window_pred.detach().cpu()\n",
    "\n",
    "        pred_audio_sequence[i*audio_window_offset:i*audio_window_offset + audio_window_length] += audio_waveform_window_pred[0] * audio_window_env\n",
    "\n",
    "    torchaudio.save(\"{}\".format(file_name), torch.reshape(pred_audio_sequence, (1, -1)), audio_sample_rate)\n",
    "\n",
    "    decoder.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a914982d-8a29-4325-8f5e-a7a41aa091de",
   "metadata": {},
   "source": [
    "## Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82884919-7719-43c0-86a3-ea751c98360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_start_time = 20\n",
    "test_audio_duration = 20\n",
    "random_walk_step_scale = 0.1\n",
    "\n",
    "test_audio_start_time_gui = widgets.FloatText(value=test_audio_start_time, description=\"Test Audio Start Time (secs):\", style={'description_width': 'initial'})\n",
    "test_audio_duration_gui = widgets.FloatText(value=test_audio_duration, description=\"Test Audio Duration (secs):\", style={'description_width': 'initial'})\n",
    "random_walk_step_scale_gui = widgets.FloatText(value=random_walk_step_scale, description=\"Random Walk Step Scale:\", style={'description_width': 'initial'})\n",
    "\n",
    "display(test_audio_start_time_gui)\n",
    "display(test_audio_duration_gui)\n",
    "display(random_walk_step_scale_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc7c2d-aab6-44b7-b8a9-ea39e6856404",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_start_time = test_audio_start_time_gui.value\n",
    "test_audio_duration = test_audio_duration_gui.value\n",
    "random_walk_step_scale = random_walk_step_scale_gui.value\n",
    "\n",
    "start_time_sample_index = int(test_audio_start_time * audio_sample_rate)\n",
    "end_time_sample_index = start_time_sample_index + int(test_audio_duration * audio_sample_rate)\n",
    "\n",
    "audio_window_offset = audio_window_length // 2\n",
    "\n",
    "latent_vectors = encode_audio(test_waveform[:, start_time_sample_index:start_time_sample_index + audio_window_length + audio_window_offset])\n",
    "audio_window_count = int(test_audio_duration * audio_sample_rate - audio_window_length) // audio_window_offset - 1\n",
    "\n",
    "for window_index in range(audio_window_count):\n",
    "    random_step = np.random.random((latent_dim)).astype(np.float32) * random_walk_step_scale\n",
    "    latent_vectors.append(latent_vectors[window_index] + random_step)\n",
    "\n",
    "decode_audio_encodings(latent_vectors, \"results/audio/randwalk_audio_epochs_{}_audio_{}-{}.wav\".format(epochs, test_audio_start_time, test_audio_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de81ea-6165-441f-88c2-9b9e481e697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequence Offset Following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed171fc5-4c29-4f5a-8f0d-e7205eed9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_start_time = 20\n",
    "test_audio_duration = 20\n",
    "offset_oscil_freq = 4.0\n",
    "offset_oscil_scale = 1.0\n",
    "\n",
    "test_audio_start_time_gui = widgets.FloatText(value=test_audio_start_time, description=\"Test Audio Start Time (secs):\", style={'description_width': 'initial'})\n",
    "test_audio_duration_gui = widgets.FloatText(value=test_audio_duration, description=\"Test Audio Duration (secs):\", style={'description_width': 'initial'})\n",
    "offset_oscil_freq_gui = widgets.FloatText(value=offset_oscil_freq, description=\"Offset Oscil Frequency:\", style={'description_width': 'initial'})\n",
    "offset_oscil_scale_gui = widgets.FloatText(value=offset_oscil_scale, description=\"Offset Oscil Scale:\", style={'description_width': 'initial'})\n",
    "\n",
    "display(test_audio_start_time_gui)\n",
    "display(test_audio_duration_gui)\n",
    "display(offset_oscil_freq_gui)\n",
    "display(offset_oscil_scale_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65db0f2-33f3-4b25-8f85-eef725142386",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_start_time = test_audio_start_time_gui.value\n",
    "test_audio_duration = test_audio_duration_gui.value\n",
    "offset_oscil_freq = offset_oscil_freq_gui.value\n",
    "offset_oscil_scale = offset_oscil_scale_gui.value\n",
    "\n",
    "start_time_sample_index = int(test_audio_start_time * audio_sample_rate)\n",
    "end_time_sample_index = start_time_sample_index + int(test_audio_duration * audio_sample_rate)\n",
    "\n",
    "latent_vectors = encode_audio(test_waveform[:, start_time_sample_index:end_time_sample_index])\n",
    "\n",
    "offset_encodings = []\n",
    "\n",
    "for index in range(len(latent_vectors)):\n",
    "    sin_value = np.sin(index / (len(latent_vectors) - 1) * np.pi * offset_oscil_freq)\n",
    "    offset = np.ones(shape=(latent_dim), dtype=np.float32) * sin_value * offset_oscil_scale\n",
    "    offset_encoding = latent_vectors[index] + offset\n",
    "    offset_encodings.append(offset_encoding)\n",
    "    \n",
    "decode_audio_encodings(offset_encodings, \"results/audio/offset_audio_epochs_{}_audio_{}-{}.wav\".format(epochs, test_audio_start_time, test_audio_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408df3f-1c14-4a45-a592-feaf8aec2610",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequence Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fa5d8a-c48f-4633-bad4-ad995602cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_audio_start_time = 20\n",
    "test2_audio_start_time = 60\n",
    "test_audio_duration = 20\n",
    "\n",
    "test1_audio_start_time_gui = widgets.FloatText(value=test1_audio_start_time, description=\"Test1 Audio Start Time (secs):\", style={'description_width': 'initial'})\n",
    "test2_audio_start_time_gui = widgets.FloatText(value=test2_audio_start_time, description=\"Test2 Audio Start Time (secs):\", style={'description_width': 'initial'})\n",
    "test_audio_duration_gui = widgets.FloatText(value=test_audio_duration, description=\"Test Audio Duration (secs):\", style={'description_width': 'initial'})\n",
    "\n",
    "display(test1_audio_start_time_gui)\n",
    "display(test2_audio_start_time_gui)\n",
    "display(test_audio_duration_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7fd57d-caeb-4cb7-8d61-1e86b57ab964",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_audio_start_time = test1_audio_start_time_gui.value\n",
    "test2_audio_start_time = test2_audio_start_time_gui.value\n",
    "test_audio_duration = test_audio_duration_gui.value\n",
    "\n",
    "start1_time_sample_index = int(test1_audio_start_time * audio_sample_rate)\n",
    "end1_time_sample_index = start1_time_sample_index + int(test_audio_duration * audio_sample_rate)\n",
    "\n",
    "start2_time_sample_index = int(test2_audio_start_time * audio_sample_rate)\n",
    "end2_time_sample_index = start2_time_sample_index + int(test_audio_duration * audio_sample_rate)\n",
    "\n",
    "latent_vectors_1 = encode_audio(test_waveform[:, start1_time_sample_index:end1_time_sample_index])\n",
    "latent_vectors_2 = encode_audio(test_waveform[:, start2_time_sample_index:end2_time_sample_index])\n",
    "\n",
    "mix_encodings = []\n",
    "\n",
    "for index in range(len(latent_vectors_1)):\n",
    "    mix_factor = index / (len(latent_vectors_1) - 1)\n",
    "    mix_encoding = latent_vectors_1[index] * (1.0 - mix_factor) + latent_vectors_2[index] * mix_factor\n",
    "    mix_encodings.append(mix_encoding)\n",
    "\n",
    "decode_audio_encodings(mix_encodings, \"results/audio/mix_audio_epochs_{}_audio1_{}-{}_audio2_{}-{}.wav\".format(epochs, test1_audio_start_time, test1_audio_start_time + test_audio_duration, test2_audio_start_time, test2_audio_start_time + test_audio_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36abb81e-eac4-43a9-a196-b2a510d12972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
